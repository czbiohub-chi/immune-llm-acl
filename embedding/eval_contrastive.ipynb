{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../benchmarks\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from benchmark import load_benchmark\n",
    "from src.mlp import MLP\n",
    "\n",
    "api_url = \"https://api.openai.com/v1\"\n",
    "api_key = input(\"OPENAI_API_KEY\")\n",
    "summary_model = \"gpt-4o-2024-11-20\"\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "benchmark_path = Path(\"../benchmarks/benchmark-difficult\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Benchmark Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist = [\n",
    "    \"SCREEN_18_HITS_ONLY.tsv\",\n",
    "    \"SCREEN_18_HITS_ONLY_FOR_INVERSE.tsv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = load_benchmark(benchmark_path)\n",
    "benchmark = benchmark[benchmark[\"screen_file\"].isin(whitelist)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings (of Summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_emb_map = {\n",
    "    \"mouse\": np.load(\"data/embeddings/genes_mouse.npy\", allow_pickle=True).item(),\n",
    "    \"human\": np.load(\"data/embeddings/genes_human.npy\", allow_pickle=True).item(),\n",
    "}\n",
    "summ_gene_emb_map = {\n",
    "    \"mouse\": np.load(\"data/embeddings/summarized_genes_mouse.npy\", allow_pickle=True).item(),\n",
    "    \"human\": np.load(\"data/embeddings/summarized_genes_human.npy\", allow_pickle=True).item(),\n",
    "}\n",
    "method_emb = np.load(\"data/embeddings/methods.npy\", allow_pickle=True).item()\n",
    "summ_method_emb = np.load(\"data/embeddings/summarized_methods.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = benchmark.drop_duplicates(\"screen_file\")\n",
    "if not os.path.exists(\"data/eval/summaries.npy\"):\n",
    "    client = OpenAI(base_url=api_url, api_key=api_key)\n",
    "    summary_prompt_files = {\n",
    "        \"cell\": \"prompts/summary-cell.json\",\n",
    "        \"phenotype\": \"prompts/summary-phenotype.json\",\n",
    "    }\n",
    "\n",
    "    summaries = dict()\n",
    "    for col, prompt_file in summary_prompt_files.items():\n",
    "        summaries[col] = dict()\n",
    "        with open(prompt_file) as f:\n",
    "            prompt_template = f.read()\n",
    "        for i, experiment in experiments.iterrows():\n",
    "            term = experiment[col]\n",
    "            prompt = json.loads(re.sub(\"\\{.*\\}\", term, prompt_template))\n",
    "            completion = client.chat.completions.create(\n",
    "                messages=prompt,\n",
    "                model=summary_model,\n",
    "                seed=42,\n",
    "                n=1,\n",
    "                temperature=0,\n",
    "                max_tokens=2048,\n",
    "            )\n",
    "            summary = completion.choices[0].message.content\n",
    "            summaries[col][term] = summary\n",
    "    np.save(\"data/eval/summaries.npy\", summaries)\n",
    "else:\n",
    "    summaries = np.load(\"data/eval/summaries.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    not os.path.exists(\"data/eval/summary_embeddings.npy\") or\n",
    "    not os.path.exists(\"data/eval/term_embeddings.npy\")\n",
    "):\n",
    "    term_embeddings = dict()\n",
    "    summary_embeddings = dict()\n",
    "    client = OpenAI(base_url=api_url, api_key=api_key)\n",
    "    for col, term_summaries in summaries.items():\n",
    "        term_embeddings[col] = dict()\n",
    "        summary_embeddings[col] = dict()\n",
    "        for term, summary in term_summaries.items():\n",
    "            out = client.embeddings.create(\n",
    "                input=[term, summary],\n",
    "                model=embedding_model,\n",
    "            )\n",
    "            term_emb = np.asarray(out.data[0].embedding)\n",
    "            summ_emb = np.asarray(out.data[1].embedding)\n",
    "            term_embeddings[col][term] = term_emb\n",
    "            summary_embeddings[col][term] = summ_emb\n",
    "    np.save(\"data/eval/summary_embeddings.npy\", summary_embeddings)\n",
    "    np.save(\"data/eval/term_embeddings.npy\", term_embeddings)\n",
    "else:\n",
    "    summary_embeddings = np.load(\"data/eval/summary_embeddings.npy\", allow_pickle=True).item()\n",
    "    term_embeddings = np.load(\"data/eval/term_embeddings.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project and Contrast Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_genome = pd.read_csv(\"../genomes/genome_homo_sapiens.tsv\", sep=\"\\t\")\n",
    "human_genome = human_genome[human_genome[\"Gene_Type\"] == \"PROTEIN_CODING\"].reset_index(drop=True)\n",
    "mouse_genome = pd.read_csv(\"../genomes/genome_mus_musculus.tsv\", sep=\"\\t\")\n",
    "mouse_genome = mouse_genome[mouse_genome[\"Gene_Type\"] == \"PROTEIN_CODING\"].reset_index(drop=True)\n",
    "\n",
    "genome_map = {\n",
    "    \"human\": human_genome,\n",
    "    \"mouse\": mouse_genome,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_model = \"27y1lds0\"\n",
    "unsumm_model = \"u30kvgtv\"\n",
    "\n",
    "def load_models(use_summarized):\n",
    "    if use_summarized:\n",
    "        sd = torch.load(f\"runs/contrastive-summarized/{summ_model}/VirtualCRISPR/{summ_model}/checkpoints/last.ckpt\", map_location=\"cpu\")\n",
    "    else:\n",
    "        sd = torch.load(f\"runs/contrastive-unsummarized/{unsumm_model}/VirtualCRISPR/{unsumm_model}/checkpoints/last.ckpt\", map_location=\"cpu\")\n",
    "    exp_sd = {k.replace(\"contraster.exp_proj.\", \"\"): v for k, v in sd[\"state_dict\"].items() if \"exp_proj\" in k}\n",
    "    gene_sd = {k.replace(\"contraster.gene_proj.\", \"\"): v for k, v in sd[\"state_dict\"].items() if \"gene_proj\" in k}\n",
    "\n",
    "    exp_proj = MLP(\n",
    "        input_dim=3072*3,\n",
    "        reduction_factor=3,\n",
    "        n_hidden=2,\n",
    "        output_dim=512,\n",
    "    )\n",
    "    exp_proj.load_state_dict(exp_sd)\n",
    "    exp_proj.eval()\n",
    "\n",
    "    gene_proj = MLP(\n",
    "        input_dim=3072,\n",
    "        reduction_factor=2,\n",
    "        n_hidden=2,\n",
    "        output_dim=512,\n",
    "    )\n",
    "    gene_proj.load_state_dict(gene_sd)\n",
    "    gene_proj.eval()\n",
    "\n",
    "    return exp_proj, gene_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for use_summarized in [True, False]:\n",
    "    print(f\"================= {'Summarized' if use_summarized else 'Unsummarized'} =================\")\n",
    "    exp_proj, gene_proj = load_models(use_summarized)\n",
    "    accs = defaultdict(list)\n",
    "    for (_, method, cell, organism, phenotype), _hits in benchmark.groupby([\"screen_file\", \"perturbation\", \"cell\", \"organism\", \"phenotype\"]):\n",
    "        method = method.title()\n",
    "        genome = genome_map[organism]\n",
    "\n",
    "        if use_summarized:\n",
    "            me = torch.as_tensor(summ_method_emb[method], dtype=torch.float32)\n",
    "            pe = torch.as_tensor(summary_embeddings[\"phenotype\"][phenotype], dtype=torch.float32)\n",
    "            ce = torch.as_tensor(summary_embeddings[\"cell\"][cell], dtype=torch.float32)\n",
    "        else:\n",
    "            me = torch.as_tensor(method_emb[method], dtype=torch.float32)\n",
    "            pe = torch.as_tensor(term_embeddings[\"phenotype\"][phenotype], dtype=torch.float32)\n",
    "            ce = torch.as_tensor(term_embeddings[\"cell\"][cell], dtype=torch.float32)\n",
    "        exp_emb = torch.concat([me, ce, pe], dim=0).unsqueeze(dim=0)\n",
    "\n",
    "        ges = []\n",
    "        for j, row in genome.iterrows():\n",
    "            gene = row[\"OFFICIAL_SYMBOL\"]\n",
    "            gene_id = row[\"IDENTIFIER_ID\"]\n",
    "            if use_summarized:\n",
    "                ge = summ_gene_emb_map[organism][gene_id]\n",
    "            else:\n",
    "                ge = gene_emb_map[organism][gene_id]\n",
    "            ges.append(ge)\n",
    "        ges = np.asarray(ges)\n",
    "        ges = torch.as_tensor(ges, dtype=torch.float32)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            exp_out = exp_proj(exp_emb)\n",
    "            gene_out = gene_proj(ges)\n",
    "        sims = cosine_similarity(exp_out, gene_out).squeeze()\n",
    "        idxs = sims.argsort()[::-1] # most similar first\n",
    "        ranked_genes = genome.loc[idxs]\n",
    "        _hits = _hits.loc[_hits[\"hit\"] == 1, \"gene\"]\n",
    "        _hits = _hits.str.lower()\n",
    "        for n in [5, 10, 50]:\n",
    "            pred = ranked_genes.iloc[:n][\"OFFICIAL_SYMBOL\"].str.lower()\n",
    "            acc = pred.isin(_hits).sum() / n\n",
    "            accs[n].append(acc)\n",
    "            # print(f\"Acc@{n}: {acc:0.3f}\")\n",
    "    for n, _accs in accs.items():\n",
    "        print(f\"Acc@{n}: {np.asarray(_accs).mean()*100:0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crispr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
